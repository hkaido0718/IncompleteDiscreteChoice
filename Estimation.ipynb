{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tianzhanyuan/IncompleteDiscreteChoice/blob/zhanyuan-patch-1/Estimation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb3pydeIf2G8"
      },
      "source": [
        "# Estimation\n",
        "\n",
        "The goal of this note is to estimate the identified set using a method by Chernozhukov, Hong, and Tamer (2007) (CHT below). Their idea is to define a sample criterion function\n",
        "\\begin{align}\n",
        "\\hat Q_n(\\theta)\n",
        "\\end{align}\n",
        "and use its level set as an estimator of $\\Theta_I(P)$.\n",
        "\n",
        "Below, we\n",
        "- generate data\n",
        "- compute conditional choice probabilities (CCPs)\n",
        "- compare CCPs with the sharp lower bound\n",
        "- define a sample criterion function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja68lsaG-0W8"
      },
      "source": [
        "# Data generation\n",
        "\n",
        "Suppose a sample is generated from an entry game.\n",
        "For this, let's simulate data from the following game.\n",
        "\n",
        "|  | $Y_2=0$ | $Y_2=1$ |\n",
        "|----------|----------|----------|\n",
        "| Enter ($Y_1=0$)  | $(0,0)$   | $(0,X_2'\\beta_2+U_2)$   |\n",
        "| Do not enter ($Y_1=1$)  | $(X_1'\\beta_1+U_1, 0)$  | $(X_1'\\beta_1+\\Delta_1+U_1,X_2'\\beta_2+\\Delta_2+U_2)$  |\n",
        "\n",
        "We set\n",
        "- $X=(X_1,X_2)$ where $X_{j},j=1,2$ are independent Bernoulli random variables.\n",
        "- $\\beta_1$ = 0.75\n",
        "- $\\beta_2$ = 0.25\n",
        "- $\\Delta_1$ = -0.5\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5 ($U_1$ and $U_2$'s correlation)\n",
        "\n",
        "The following code generates data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfxkmyqdCtV7",
        "outputId": "3a8b946f-3a00-42dc-83f2-dd9a887d1b6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0.]\n",
            " [1. 1.]\n",
            " [1. 0.]\n",
            " ...\n",
            " [0. 1.]\n",
            " [0. 0.]\n",
            " [0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def simulate_y(n, beta1, beta2, delta1, delta2, rho, Y_nodes, seed=None):\n",
        "    \"\"\"\n",
        "    Simulate Y based on given parameters and regions, and store X and Y values.\n",
        "\n",
        "    Parameters:\n",
        "    n (int): Number of simulations\n",
        "    rho (float): Correlation coefficient between U1 and U2\n",
        "    beta1 (float): Coefficient for U1\n",
        "    beta2 (float): Coefficient for U2\n",
        "    delta1 (float): Threshold adjustment for region01\n",
        "    delta2 (float): Threshold adjustment for region10\n",
        "    Y_nodes (list of tuples): Possible values for Y\n",
        "    seed (int, optional): Seed for the random number generator\n",
        "\n",
        "    Returns:\n",
        "    tuple: Two numpy arrays, X_vals and Y, both of shape (n, 2)\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        np.random.seed(seed)\n",
        "\n",
        "    # Covariance matrix for the bivariate normal distribution\n",
        "    cov = [[1, rho], [rho, 1]]\n",
        "\n",
        "    # Storage for the results\n",
        "    Y = np.zeros((n, 2))\n",
        "    X_vals = np.zeros((n, 2))\n",
        "\n",
        "    # Simulation\n",
        "    for i in range(n):\n",
        "        # Generate U from a bivariate normal distribution\n",
        "        U = np.random.multivariate_normal([0, 0], cov)\n",
        "\n",
        "        # Generate X from independent Bernoulli distributions\n",
        "        X = np.random.binomial(1, 0.5, 2)\n",
        "        #X = np.random.standard_normal(2)\n",
        "        X_vals[i] = X\n",
        "\n",
        "        # Calculate the threshold values for regions\n",
        "        threshold1_00 = -X[0] * beta1\n",
        "        threshold2_00 = -X[1] * beta2\n",
        "        threshold1_01 = -X[0] * beta1 - delta1\n",
        "        threshold2_10 = -X[1] * beta2 - delta2\n",
        "\n",
        "        # Determine the region and assign Y\n",
        "        if U[0] <= threshold1_00 and U[1] <= threshold2_00:\n",
        "            Y[i] = Y_nodes[0]\n",
        "        elif U[0] <= threshold1_01 and U[1] >= threshold2_00 and not (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[1]\n",
        "        elif U[0] >= threshold1_00 and U[1] <= threshold2_10 and not (U[0] <= threshold1_01 and U[1] >= threshold2_00):\n",
        "            Y[i] = Y_nodes[2]\n",
        "        elif U[0] >= threshold1_01 and U[1] >= threshold2_10:\n",
        "            Y[i] = Y_nodes[3]\n",
        "        elif (U[0] <= threshold1_01 and U[1] >= threshold2_00) and (U[0] >= threshold1_00 and U[1] <= threshold2_10):\n",
        "            Y[i] = Y_nodes[np.random.choice([1, 2])]\n",
        "\n",
        "    return X_vals, Y\n",
        "\n",
        "# Example usage\n",
        "n = 1000\n",
        "beta1 = 0.75\n",
        "beta2 = 0.25\n",
        "delta1 = -0.5\n",
        "delta2 = -0.5\n",
        "rho = 0.5\n",
        "theta_true = [beta1, beta2, delta1, delta2, rho]\n",
        "Y_nodes = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
        "seed = 123\n",
        "\n",
        "# Simulate the values\n",
        "X, Y = simulate_y(n, rho, beta1, beta2, delta1, delta2, Y_nodes,seed=seed)\n",
        "print(Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yhdjBqDhJvd"
      },
      "source": [
        "# Computing CCP\n",
        "Now let's compute the sample conditional choice probabilities, which we can use to construct a sample criterion function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_4pDFqeZl-p",
        "outputId": "a791e57e-c85f-4e04-ec57-72d07c2a11fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IncompleteDiscreteChoice'...\n",
            "remote: Enumerating objects: 399, done.\u001b[K\n",
            "remote: Counting objects: 100% (135/135), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 399 (delta 76), reused 57 (delta 36), pack-reused 264 (from 1)\u001b[K\n",
            "Receiving objects: 100% (399/399), 1.25 MiB | 9.38 MiB/s, done.\n",
            "Resolving deltas: 100% (219/219), done.\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.12/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.7.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!rm -rf IncompleteDiscreteChoice\n",
        "!git clone --branch zhanyuan-patch-1 --single-branch https://github.com/tianzhanyuan/IncompleteDiscreteChoice.git\n",
        "!pip install scikit-optimize\n",
        "\n",
        "import IncompleteDiscreteChoice.idclib_undi as idc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idc library has a function called calculate_ccp. For this, we should pass the data ($Y,X$) and their support."
      ],
      "metadata": {
        "id": "fHvsZ7U9hLne"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aD4rDHsAhLmd",
        "outputId": "80953658-723f-469b-d3cc-dfa3626330dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(Y|X=(np.float64(0.0), np.float64(1.0))) = {(0, 0): 0.08171206225680934, (0, 1): 0.3852140077821012, (1, 0): 0.26459143968871596, (1, 1): 0.26848249027237353}\n",
            "P(Y|X=(np.float64(1.0), np.float64(1.0))) = {(0, 0): 0.05982905982905983, (0, 1): 0.15384615384615385, (1, 0): 0.33760683760683763, (1, 1): 0.44871794871794873}\n",
            "P(Y|X=(np.float64(0.0), np.float64(0.0))) = {(0, 0): 0.1857707509881423, (0, 1): 0.2924901185770751, (1, 0): 0.391304347826087, (1, 1): 0.13043478260869565}\n",
            "P(Y|X=(np.float64(1.0), np.float64(0.0))) = {(0, 0): 0.10546875, (0, 1): 0.15625, (1, 0): 0.53515625, (1, 1): 0.203125}\n",
            "[(np.float64(0.0), np.float64(0.0)), (np.float64(0.0), np.float64(1.0)), (np.float64(1.0), np.float64(0.0)), (np.float64(1.0), np.float64(1.0))]\n",
            "[0.253 0.257 0.256 0.234]\n",
            "[[0.18577075 0.29249012 0.39130435 0.13043478]\n",
            " [0.08171206 0.38521401 0.26459144 0.26848249]\n",
            " [0.10546875 0.15625    0.53515625 0.203125  ]\n",
            " [0.05982906 0.15384615 0.33760684 0.44871795]]\n"
          ]
        }
      ],
      "source": [
        "conditional_probabilities,ccp_array, Px, X_supp = idc.calculate_ccp(Y,X, Y_nodes)\n",
        "\n",
        "# Print the conditional probabilities for the specified X support\n",
        "for x in list(conditional_probabilities.keys())[:5]:\n",
        "    print(f\"P(Y|X={x}) = {conditional_probabilities[x]}\")\n",
        "\n",
        "# Support of X and X's marginal distribution over it\n",
        "print(X_supp)\n",
        "print(Px)\n",
        "\n",
        "# This is the CCP matrix (sorted according to X_supp)\n",
        "print(ccp_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUktkjH3zXmC"
      },
      "source": [
        "From the CCP, we can compute the conditional probability of all events $P(A|X_i),A\\subseteq\\mathcal Y$ for each $X_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aDTNoutXkhWW",
        "outputId": "ca626b5e-9929-4670-efff-0d1225cbb977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            " 0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            " 0.60869565 0.70750988 0.81422925 1.        ]\n",
            "[[0.         0.18577075 0.29249012 0.39130435 0.13043478 0.47826087\n",
            "  0.5770751  0.31620553 0.68379447 0.4229249  0.52173913 0.86956522\n",
            "  0.60869565 0.70750988 0.81422925 1.        ]\n",
            " [0.         0.08171206 0.38521401 0.26459144 0.26848249 0.46692607\n",
            "  0.3463035  0.35019455 0.64980545 0.6536965  0.53307393 0.73151751\n",
            "  0.73540856 0.61478599 0.91828794 1.        ]\n",
            " [0.         0.10546875 0.15625    0.53515625 0.203125   0.26171875\n",
            "  0.640625   0.30859375 0.69140625 0.359375   0.73828125 0.796875\n",
            "  0.46484375 0.84375    0.89453125 1.        ]\n",
            " [0.         0.05982906 0.15384615 0.33760684 0.44871795 0.21367521\n",
            "  0.3974359  0.50854701 0.49145299 0.6025641  0.78632479 0.55128205\n",
            "  0.66239316 0.84615385 0.94017094 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "_, temp = idc.calculate_subset_probabilities(ccp_array[0,:], Y_nodes)\n",
        "print(temp)\n",
        "J = len(temp) # This is the number of all events\n",
        "\n",
        "Nx = len(ccp_array) # number of unique X values (n for continous X)\n",
        "p_events = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "  _, p_events[i,:] = idc.calculate_subset_probabilities(ccp_array[i,:], Y_nodes)\n",
        "\n",
        "# Printing p(A|x) as an Nx-by-J array\n",
        "print(p_events)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0ftK4DVZiZW"
      },
      "source": [
        "# Compute sharp lower bound $\\nu_\\theta(A|x)$\n",
        "Now, let's compare $P(A|X_i)$ to the sharp lower bound calculated at some value $\\theta$. For the moment, we use the following value as $\\theta$ (you can change it to something else.)\n",
        "- $\\beta_1$ = 0.5\n",
        "- $\\beta_2$ = 0.5\n",
        "- $\\Delta_1$ = -0.25\n",
        "- $\\Delta_2$ = -0.5\n",
        "- $\\rho$ = 0.5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DYC7rSxcF14"
      },
      "source": [
        "As before let's build a model as a graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CNlRSA4kb1SO"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGI0KEdscVAe"
      },
      "source": [
        "The next step is to calculate the probability distribution $F_\\theta(\\cdot|X_i)$ over the $U$-nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_I9N4PTcZhy",
        "outputId": "e2c99e13-27a3-4e8b-feb9-5bd5ec1fcad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.33333217 0.19694609 0.25122617 0.19659913 0.02189845]\n",
            " [0.22687747 0.32529884 0.14563479 0.28116187 0.02103467]\n",
            " [0.22688203 0.10152299 0.40061467 0.25237197 0.01861066]\n",
            " [0.16331975 0.18369635 0.25212357 0.37986425 0.02099885]]\n"
          ]
        }
      ],
      "source": [
        "import IncompleteDiscreteChoice.examples as idcex\n",
        "\n",
        "theta_temp = [0.5,0.5,-0.25,-0.5,0.5]\n",
        "Nu = len(U_nodes)\n",
        "Ftheta = np.zeros((Nx,Nu))\n",
        "for i in range(Nx):\n",
        "  Ftheta[i,:] = idcex.calculate_Ftheta_entrygame(X_supp[i],theta_temp)\n",
        "\n",
        "# Print Ftheta as Nx-by-Nu array\n",
        "print(Ftheta)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oli2qywycqbj"
      },
      "source": [
        "Now we are ready to compute the sharp lower bound of CCPs at $\\theta$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPFL4Wmucv0G",
        "outputId": "97930236-a845-42f5-b6bd-ead1f7de2853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.33333217 0.19694609 0.25122617 0.19659913 0.53027827\n",
            "  0.58455834 0.5299313  0.47007071 0.39354523 0.4478253  0.80340289\n",
            "  0.7268774  0.78115747 0.66666985 1.00000202]\n",
            " [0.         0.22687747 0.32529884 0.14563479 0.28116187 0.55217631\n",
            "  0.37251227 0.50803934 0.49196831 0.60646071 0.42679666 0.71884578\n",
            "  0.83333818 0.65367413 0.77313017 1.00000764]\n",
            " [0.         0.22688203 0.10152299 0.40061467 0.25237197 0.32840503\n",
            "  0.6274967  0.479254   0.52074832 0.35389496 0.65298663 0.74763035\n",
            "  0.58077699 0.87986867 0.77312029 1.00000232]\n",
            " [0.         0.16331975 0.18369635 0.25212357 0.37986425 0.3470161\n",
            "  0.41544331 0.543184   0.45681877 0.56356061 0.63198782 0.62013851\n",
            "  0.72688035 0.79530757 0.83668302 1.00000277]]\n"
          ]
        }
      ],
      "source": [
        "nutheta = np.zeros((Nx,J))\n",
        "for i in range(Nx):\n",
        "    _,nutheta[i,:] = gmodel.calculate_sharp_lower_bound(Ftheta[i])\n",
        "\n",
        "# Print lower bound as Nx-by-J array (compare it to p(A|x) above)\n",
        "print(nutheta)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4j6M8yDrDP2"
      },
      "source": [
        "Now let's compare the CCP and lower bounds and compute $\\hat Q_n(\\theta)=\\frac{1}{n}\\sum_{j}\\sum_{x\\in\\mathcal X}w_x(\\nu_\\theta(A_j|x)-\\hat P_n(A_j|x))_+$,\n",
        "where $w_x=\\sum_{i}1\\{X_i=x\\}/n$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQlwG4M2tImH",
        "outputId": "d9be2409-fb63-402a-972d-47b19859d0fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005659745511206443\n"
          ]
        }
      ],
      "source": [
        "difference = nutheta - p_events\n",
        "diff_pos = np.maximum(difference, 0)\n",
        "w = np.repeat(Px,J).reshape(Nx,J)\n",
        "n = len(Y)\n",
        "Qhat = np.sum(w*diff_pos)/n\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXAGIe0LkAQC"
      },
      "source": [
        "# Summary\n",
        "\n",
        "Let's summarize what we did:\n",
        "- We computed $\\hat p(A|x)$\n",
        "- We computed $\\nu_\\theta(A|x)$ at $\\theta$\n",
        "- We computed $\\hat Q_n(\\theta)$\n",
        "\n",
        "The IDC library has a wrapper function `idc.calculate_Qhat` to execute the steps avove.\n",
        "\n",
        "It takes the following objects as inputs\n",
        "- theta: (parameter)\n",
        "- [Y,X]: (data)\n",
        "- gmodel: (class BipartiteGraph)\n",
        "  - Y-nodes\n",
        "  - U-nodes\n",
        "  - Edges\n",
        "- calculate_Ftheta (function)\n",
        "\n",
        "You can simply execute the following code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRr59lJnrYV",
        "outputId": "18681e6d-8f2a-40a9-af54-289ccb83255f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0005659618486779784\n"
          ]
        }
      ],
      "source": [
        "# If needed uncomment the line below\n",
        "#!git clone https://github.com/hkaido0718/IncompleteDiscreteChoice.git\n",
        "import IncompleteDiscreteChoice.idclib as idc\n",
        "import IncompleteDiscreteChoice.examples as ex\n",
        "import numpy as np\n",
        "import gdown\n",
        "\n",
        "# Download entrygame sample data (same data as above)\n",
        "url = \"https://drive.google.com/uc?id=1cRhMJ8bRhdzy9_agmQ_LkqzlsKRKcthX\"\n",
        "output = \"data_entrygame.npz\"\n",
        "gdown.download(url, output, quiet=True)\n",
        "Data = np.load(output, allow_pickle=True)\n",
        "\n",
        "# Define the nodes\n",
        "Y_nodes = [(0,0), (0,1), (1,0), (1,1)]\n",
        "U_nodes = ['a', 'b', 'c', 'd', 'e']\n",
        "\n",
        "# Create edges\n",
        "edges = [\n",
        "    ('a', (0,0)),\n",
        "    ('b', (0,1)),\n",
        "    ('c', (1,0)),\n",
        "    ('d', (1,1)),\n",
        "    ('e', (0,1)),\n",
        "    ('e', (1,0))\n",
        "]\n",
        "\n",
        "gmodel = idc.BipartiteGraph(Y_nodes, U_nodes, edges)\n",
        "theta = [0.5, 0.5, -0.25, -0.5, 0.5]\n",
        "Y = Data['Y']\n",
        "X = Data['X']\n",
        "data = [Y, X]\n",
        "Qhat = idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "print(Qhat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLwnDkLHRTsc"
      },
      "source": [
        "You can use `calculate_Qhat` to construct a consistent estimator or construct other test statistics. As an exercise, let's find a minimizer (a point in a consistent set estimator) of this objective function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyAsFqsZRX1z",
        "outputId": "5a04eb72-b248-4039-8f4b-96e94e561a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.00035024856313470553\n",
            "Convergence: 0.02633210718176702\n",
            "Constraint violated: Ftheta values below 1e-06. Applying penalty.\n",
            "Current Qhat: 0.00035025104860997124\n",
            "Convergence: 0.026493928393916816\n",
            "Current Qhat: 0.0003502377605236614\n",
            "Convergence: 0.03464517578521331\n",
            "Current Qhat: 0.0002614104390008683\n",
            "Convergence: 0.03868508181012649\n",
            "Current Qhat: 0.00025728406174357633\n",
            "Convergence: 0.03821389161662461\n",
            "Current Qhat: 0.00025726618563148477\n",
            "Convergence: 0.037791426015434046\n",
            "Current Qhat: 0.0002485964600751821\n",
            "Convergence: 0.040607134181444855\n",
            "Current Qhat: 0.00021859201858263\n",
            "Convergence: 0.03966209212480204\n",
            "Current Qhat: 0.00020937653744432626\n",
            "Convergence: 0.04293778015561267\n",
            "Current Qhat: 0.0002041899142067351\n",
            "Convergence: 0.04445174203431253\n",
            "Current Qhat: 0.0002041873506227861\n",
            "Convergence: 0.045935151282050175\n",
            "Current Qhat: 0.00020418865573255867\n",
            "Convergence: 0.05172346559465733\n",
            "Current Qhat: 0.00020418755335023007\n",
            "Convergence: 0.05937972230927138\n",
            "Current Qhat: 0.00018862616325032673\n",
            "Convergence: 0.05976646436244913\n",
            "Current Qhat: 0.0001856013362978094\n",
            "Convergence: 0.08495412904574083\n",
            "Current Qhat: 0.00018373072712698967\n",
            "Convergence: 0.08953028955717725\n",
            "Current Qhat: 0.00018110510893465232\n",
            "Convergence: 0.1050844700751446\n",
            "Current Qhat: 0.0001804874151217862\n",
            "Convergence: 0.11410789979334804\n",
            "Current Qhat: 0.00017717035932103607\n",
            "Convergence: 0.13837708027884776\n",
            "Current Qhat: 0.0001771738168432619\n",
            "Convergence: 0.1419143767750894\n",
            "Current Qhat: 0.00017689286447284766\n",
            "Convergence: 0.23274300406790285\n",
            "Current Qhat: 0.0001764172926104279\n",
            "Convergence: 0.3050269708254785\n",
            "Current Qhat: 0.00017552635174548762\n",
            "Convergence: 0.3566308564062805\n",
            "Current Qhat: 0.00017552642956367913\n",
            "Convergence: 0.4046083863581685\n",
            "Current Qhat: 0.0001753535865094406\n",
            "Convergence: 0.41369876978419456\n",
            "Current Qhat: 0.00017535482739744834\n",
            "Convergence: 0.4405263944048283\n",
            "Current Qhat: 0.00017452651752929174\n",
            "Convergence: 0.4906567347874613\n",
            "Current Qhat: 0.0001739046335537796\n",
            "Convergence: 0.5661870209259356\n",
            "Current Qhat: 0.00017386739902099208\n",
            "Convergence: 0.5800292835587045\n",
            "Current Qhat: 0.00017386602731683703\n",
            "Convergence: 0.5891245679259648\n",
            "Current Qhat: 0.00017379382295774228\n",
            "Convergence: 0.7262385857676238\n",
            "Current Qhat: 0.00017344173820738574\n",
            "Convergence: 0.7872672947628814\n",
            "Current Qhat: 0.00017344095741663595\n",
            "Convergence: 0.7982075103553254\n",
            "Current Qhat: 0.00017344142896857738\n",
            "Convergence: 1.2032526492286335\n",
            "Optimal theta: [ 0.70865351  0.72455609 -0.0601195  -0.60029877  0.00138245]\n",
            "Minimum Qhat: 0.00017344095090080357\n"
          ]
        }
      ],
      "source": [
        "from scipy.optimize import differential_evolution\n",
        "\n",
        "# Assuming the calculate_Qhat function is already defined as provided earlier\n",
        "\n",
        "# Define the function to minimize\n",
        "def objective_function(theta):\n",
        "    return idc.calculate_Qhat(theta, data, gmodel, ex.calculate_Ftheta_entrygame)\n",
        "\n",
        "# Define the bounds\n",
        "LB = [-2, -2, -2, -2, 0]\n",
        "UB = [2, 2, 0, 0, 0.85]\n",
        "bounds = [(low, high) for low, high in zip(LB, UB)]\n",
        "\n",
        "# Callback function to print intermediate results\n",
        "def callback(xk, convergence):\n",
        "    #print(f\"Current theta: {xk}\")\n",
        "    print(f\"Current Qhat: {objective_function(xk)}\")\n",
        "    print(f\"Convergence: {convergence}\")\n",
        "\n",
        "# Set a seed for replicability\n",
        "np.random.seed(123)\n",
        "\n",
        "# Perform the optimization\n",
        "result = differential_evolution(objective_function, bounds, callback=callback,seed=123)\n",
        "\n",
        "# Get the optimal theta and the minimum Qhat value\n",
        "optimal_theta = result.x\n",
        "min_Qhat = result.fun\n",
        "\n",
        "print(\"Optimal theta:\", optimal_theta)\n",
        "print(\"Minimum Qhat:\", min_Qhat)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}